{
 "metadata": {
  "name": "",
  "signature": "sha256:5a711f0ddcd8141a768000f10f1d14448ab94bcd11dec2e19ba8c1d0ca31a7d7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from edx.idea.data_frame import DataFrame\n",
      "from edx.idea.sql import sql_query\n",
      "from collections import namedtuple"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Loading data to work with"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = DataFrame.from_url('gibberish.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the following command only reads part of the file and returns the first 5 lines. It need not read the entire file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.take(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[u'Lorem ipsum dolor sit amet, consectetur adipiscing elit.',\n",
        " u'Integer euismod lacus nec mi dignissim porta.',\n",
        " u'Aenean vel libero ac nulla sodales lacinia in vitae ex.',\n",
        " u'Fusce vitae orci id erat pretium aliquet et vel augue.',\n",
        " u'Aenean cursus nisl vitae facilisis vehicula.']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Word Count (obligatory)\n",
      "\n",
      "Below is the classic word count problem implemented using this API. Note that the `wc_mapper` and `wc_reducer` closures are actually serialized and shipped to slave nodes to execute over various partitions of the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def wc_mapper(line):\n",
      "    for word in line.split(' '):\n",
      "        yield (word.rstrip(\".,\\r\\n\").lower(), 1)\n",
      "\n",
      "def wc_reducer(word, counts):\n",
      "    yield (word, sum(counts))\n",
      "\n",
      "counted_words = df.map_reduce(wc_mapper, wc_reducer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After the previous code was executed, no computation has actually been done. Once I actually request the results of the compuation, it is the promise is resolved, data is computed and then returned to the driver."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict(counted_words.collect()[:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "{u'ac': 18,\n",
        " u'auctor': 14,\n",
        " u'felis': 14,\n",
        " u'justo': 8,\n",
        " u'quam': 6,\n",
        " u'sagittis': 6,\n",
        " u'semper': 8,\n",
        " u'suscipit': 9,\n",
        " u'urna': 17,\n",
        " u'varius': 4}"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## SQL"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TextLine = namedtuple('TextLine', ['line'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to know what to call columns etc, the data must be structured somewhat. We use a namedtuple to provide that structure, assigning names to values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert(l):\n",
      "    yield TextLine(line=l)\n",
      "df2 = df.map(convert)\n",
      "df2.take(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[TextLine(line=u'Lorem ipsum dolor sit amet, consectetur adipiscing elit.')]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can then save the DataFrame as a table. Note that this overwrites any existing table with that name."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2.to_table(table_name='gibberish')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Deleted file:///tmp/spark/warehouse/gibberish\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<edx.idea.data_frame.DataFrame at 0x7f2dde515fd0>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = sql_query('SELECT line FROM gibberish')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, this SQL query has not yet been executed, it is not until we actually try to use the results that it is run."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res.take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[Row(line=u'Nullam ut enim in urna hendrerit luctus et ut leo.'),\n",
        " Row(line=u'Aenean lacinia metus a ipsum bibendum egestas.'),\n",
        " Row(line=u'Phasellus nec arcu dapibus, elementum ex sit amet, dapibus sem.'),\n",
        " Row(line=u'Integer feugiat magna eget urna porta, at faucibus eros molestie.'),\n",
        " Row(line=u'Nullam faucibus odio porttitor, fermentum felis eget, consectetur augue.'),\n",
        " Row(line=u'Vivamus in massa sed sem vulputate pellentesque.'),\n",
        " Row(line=u'Nunc nec orci eget purus ullamcorper auctor eget eu justo.'),\n",
        " Row(line=u'Maecenas nec turpis ac nisl pharetra condimentum at sed sem.'),\n",
        " Row(line=u'Proin viverra turpis at blandit sollicitudin.'),\n",
        " Row(line=u'Vestibulum et risus feugiat, molestie dolor nec, ultrices sapien.')]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tables can be partitioned using a primary key. When writing to a partioned table, only the modified partitions are overwritten.\n",
      "\n",
      "Note that if a partition is written to, it is entirely overwritten, so the replacement data must be complete."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PartitionedTextLine = namedtuple('TextLine', ['partition', 'line'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def part_convert(l):\n",
      "    yield PartitionedTextLine(partition=(len(l) % 5), line=l)\n",
      "part_df = df.map(part_convert)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "part_df.to_table(table_name='partitioned', primary_key='partition')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Deleted file:///tmp/spark/warehouse/partitioned/partition=3\n",
        "Deleted file:///tmp/spark/warehouse/partitioned/partition=2\n",
        "Deleted file:///tmp/spark/warehouse/partitioned/partition=4\n",
        "Deleted file:///tmp/spark/warehouse/partitioned/partition=1\n",
        "Deleted file:///tmp/spark/warehouse/partitioned/partition=0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<edx.idea.data_frame.DataFrame at 0x7f2dde4cdc50>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note the first few records of partition 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql_query(\"SELECT line FROM partitioned WHERE partition=0 LIMIT 10\").collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[Row(line=u'Nullam ut enim in urna hendrerit luctus et ut leo.'),\n",
        " Row(line=u'Integer feugiat magna eget urna porta, at faucibus eros molestie.'),\n",
        " Row(line=u'Maecenas nec turpis ac nisl pharetra condimentum at sed sem.'),\n",
        " Row(line=u'Proin viverra turpis at blandit sollicitudin.'),\n",
        " Row(line=u'Vestibulum et risus feugiat, molestie dolor nec, ultrices sapien.'),\n",
        " Row(line=u'Quisque at ante faucibus, pellentesque velit elementum, ullamcorper tellus.'),\n",
        " Row(line=u'Cras et turpis non augue porta vehicula.'),\n",
        " Row(line=u'Etiam ac sem commodo, rutrum urna id, elementum turpis.'),\n",
        " Row(line=u'Nam eget quam bibendum, aliquam nunc vitae, consequat massa.'),\n",
        " Row(line=u'Etiam non justo convallis, sollicitudin erat vel, suscipit justo.')]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we create a new DataFrame containing records only in partition 0 and convert all of the strings to upper case.\n",
      "\n",
      "Note that when we call `to_table` on this DataFrame it only replaces partition 0, all other partitions are untouched."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def part_convert_upper(l):\n",
      "    part = len(l) % 5\n",
      "    if part == 0:\n",
      "        yield PartitionedTextLine(partition=part, line=l.upper())\n",
      "\n",
      "df.map(part_convert_upper).to_table(table_name='partitioned', primary_key='partition')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Deleted file:///tmp/spark/warehouse/partitioned/partition=0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<edx.idea.data_frame.DataFrame at 0x7f2dde4dd610>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Partition 0 records are now all uppercase."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql_query(\"SELECT line FROM partitioned WHERE partition=0 LIMIT 10\").collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "[Row(line=u'NULLAM UT ENIM IN URNA HENDRERIT LUCTUS ET UT LEO.'),\n",
        " Row(line=u'INTEGER FEUGIAT MAGNA EGET URNA PORTA, AT FAUCIBUS EROS MOLESTIE.'),\n",
        " Row(line=u'MAECENAS NEC TURPIS AC NISL PHARETRA CONDIMENTUM AT SED SEM.'),\n",
        " Row(line=u'PROIN VIVERRA TURPIS AT BLANDIT SOLLICITUDIN.'),\n",
        " Row(line=u'VESTIBULUM ET RISUS FEUGIAT, MOLESTIE DOLOR NEC, ULTRICES SAPIEN.'),\n",
        " Row(line=u'QUISQUE AT ANTE FAUCIBUS, PELLENTESQUE VELIT ELEMENTUM, ULLAMCORPER TELLUS.'),\n",
        " Row(line=u'CRAS ET TURPIS NON AUGUE PORTA VEHICULA.'),\n",
        " Row(line=u'ETIAM AC SEM COMMODO, RUTRUM URNA ID, ELEMENTUM TURPIS.'),\n",
        " Row(line=u'NAM EGET QUAM BIBENDUM, ALIQUAM NUNC VITAE, CONSEQUAT MASSA.'),\n",
        " Row(line=u'ETIAM NON JUSTO CONVALLIS, SOLLICITUDIN ERAT VEL, SUSCIPIT JUSTO.')]"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other partitions are still there and still lowercase."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sql_query(\"SELECT line FROM partitioned WHERE partition=1 LIMIT 10\").collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "[Row(line=u'Aenean lacinia metus a ipsum bibendum egestas.'),\n",
        " Row(line=u'Quisque et nisi nec ipsum dictum lobortis at vitae urna.'),\n",
        " Row(line=u'Duis vitae erat tempus dui fringilla accumsan.'),\n",
        " Row(line=u'Donec porttitor neque at nulla rutrum blandit.'),\n",
        " Row(line=u'Nunc at est et leo mollis tristique.'),\n",
        " Row(line=u'Donec lobortis metus et mi dignissim suscipit.'),\n",
        " Row(line=u'Duis et mi nec erat elementum egestas vel ut nulla.'),\n",
        " Row(line=u'Integer et nunc non augue rutrum vulputate ut in tellus.'),\n",
        " Row(line=u'Fusce quis eros eu urna elementum efficitur id eget dui.'),\n",
        " Row(line=u'Morbi ut tortor eu felis gravida lacinia euismod ut dui.')]"
       ]
      }
     ],
     "prompt_number": 17
    }
   ],
   "metadata": {}
  }
 ]
}